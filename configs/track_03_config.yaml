# Track 03: Multi-Agent Coordination Benchmarks Configuration
# Purpose: Evaluate coordination patterns between multiple AI agents
# Author: Deepak Soni
# License: MIT

track:
  id: "track_03"
  name: "Multi-Agent Coordination Benchmarks"
  description: "Evaluate task delegation, message passing, and consensus mechanisms"

# Agent Configurations
agents:
  frameworks:
    - name: "langgraph"
      enabled: true
      description: "LangGraph stateful agent graphs"
    - name: "crewai"
      enabled: true
      description: "CrewAI role-based agents"
    - name: "autogen"
      enabled: true
      description: "AutoGen conversational agents"

  roles:
    - name: "orchestrator"
      description: "High-level task planning and delegation"
    - name: "researcher"
      description: "Information gathering and synthesis"
    - name: "analyst"
      description: "Data analysis and reasoning"
    - name: "writer"
      description: "Content creation and summarization"
    - name: "reviewer"
      description: "Quality assurance and validation"

# Hierarchical Coordination Benchmarks
hierarchical:
  enabled: true
  description: "Manager-worker delegation patterns"

  config:
    max_depth: 3
    max_workers_per_manager: 4
    delegation_strategy: "capability_based"

  benchmarks:
    # Document Review Pipeline
    document_review:
      name: "Multi-stage Document Review"
      samples: 8
      max_tokens: 2000
      agents: ["orchestrator", "researcher", "analyst", "writer", "reviewer"]
      metrics:
        - delegation_accuracy
        - task_completion_rate
        - quality_score
        - coordination_overhead

    # Research Synthesis
    research_synthesis:
      name: "Research Synthesis Pipeline"
      samples: 8
      max_tokens: 2500
      agents: ["orchestrator", "researcher", "analyst", "writer"]
      metrics:
        - information_coverage
        - synthesis_coherence
        - pipeline_efficiency

    # Code Review Pipeline
    code_review:
      name: "Multi-specialist Code Review"
      samples: 10
      max_tokens: 1800
      agents: ["orchestrator", "security_analyst", "performance_analyst", "reviewer"]
      metrics:
        - issue_detection_rate
        - false_positive_rate
        - review_completeness

# Collaborative Coordination Benchmarks
collaborative:
  enabled: true
  description: "Peer-to-peer collaboration patterns"

  config:
    max_agents: 5
    communication_pattern: "broadcast"  # broadcast, ring, or mesh
    consensus_threshold: 0.6

  benchmarks:
    # Collaborative Problem Solving
    problem_solving:
      name: "Collaborative Problem Solving"
      samples: 8
      max_tokens: 2000
      agents: ["analyst_1", "analyst_2", "analyst_3"]
      metrics:
        - solution_diversity
        - consensus_time
        - solution_quality
        - contribution_balance

    # Debate and Synthesis
    debate:
      name: "Multi-perspective Debate"
      samples: 6
      max_tokens: 3000
      agents: ["advocate_pro", "advocate_con", "synthesizer"]
      metrics:
        - argument_quality
        - counterargument_effectiveness
        - synthesis_balance

    # Error Correction
    error_correction:
      name: "Collaborative Error Detection"
      samples: 10
      max_tokens: 1500
      agents: ["checker_1", "checker_2", "aggregator"]
      metrics:
        - error_detection_rate
        - false_alarm_rate
        - correction_accuracy

# Competitive Coordination Benchmarks
competitive:
  enabled: true
  description: "Proposal, voting, and selection patterns"

  config:
    max_proposals: 5
    voting_strategy: "ranked_choice"
    selection_criteria: "quality_weighted"

  benchmarks:
    # Solution Competition
    solution_competition:
      name: "Best Solution Selection"
      samples: 8
      max_tokens: 2000
      agents: ["proposer_1", "proposer_2", "proposer_3", "judge"]
      metrics:
        - proposal_diversity
        - selection_accuracy
        - winner_quality

    # Creative Competition
    creative_competition:
      name: "Creative Idea Generation"
      samples: 6
      max_tokens: 1500
      agents: ["creative_1", "creative_2", "creative_3", "evaluator"]
      metrics:
        - idea_novelty
        - idea_feasibility
        - evaluation_consistency

# Communication Efficiency
communication:
  description: "Evaluate inter-agent communication efficiency"

  metrics:
    - name: "message_count"
      description: "Total messages exchanged"
      weight: 0.20
    - name: "message_relevance"
      description: "Percentage of useful messages"
      weight: 0.25
    - name: "latency"
      description: "Time to reach consensus/completion"
      weight: 0.25
    - name: "bandwidth"
      description: "Total tokens exchanged"
      weight: 0.15
    - name: "convergence"
      description: "How quickly agents align"
      weight: 0.15

# Protocols
protocols:
  a2a:
    enabled: true
    description: "Agent-to-Agent Protocol evaluation"
    features:
      - agent_discovery
      - capability_negotiation
      - task_delegation
      - result_aggregation

# Output Configuration
output:
  directory: "tracks/track_03_multi_agent/results"
  format: ["json"]
  save_conversation_logs: true
  save_agent_states: true
  save_coordination_graphs: true
